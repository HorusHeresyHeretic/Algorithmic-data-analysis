# Algorithmic-data-analysis
Disclaimer: мои симпатии на этой [стороне](https://t.me/grey_zone).

Привет. Я решил ещё раз устроиться на работу DS и для этого я расскажу вам о части моего опыта, полученного в топ1 предприятии отрасли. Будет немного кода, много картинок, несколько графиков. Это скорее презентация, чем  гайд, но возможно кто-то сможет научиться здесь чему то полезному. Markdown я уже подзабыл, поэтому особо красиво не будет.

## [Cаундтрек](https://youtu.be/kcS-xmd4MMQ) для чтения, часть 0.

В далёких годах в одной из конференций энтузиастов, которая сложились вокруг первого запуска Mlopen (все тогда горели желанием познать новую технологию, которую принёс нам Yorko и co и собирались по интересам в рамках броуновского движения в группы, которые грызли гранит науки сообща) людей, желающих научиться было много.

В настоящем из почти 20 человек кто начал этот путь в нашей конфе, в России остался работать только я, последние уехали недавно. Плюс кто-то не вкатился или не смог устроиться на работу джуном и плюнул. 

И это показатель, потому что наша конфа по качеству специалистов одна из лучших. Дефицит кадров будет усугубляться, но что более важно будет происходить снижение качества этих кадров. Человек, который умеет в t-sql и немного в pandas это не DS, это дата инженера пытаются натянуть на глобус.

Дальше будет хуже. Учебные курсы последних лет по специальности DS я видел - херня, выпускников ШАД с гит под копирку и пустым взглядом на собеседованиях тоже наблюдал, пожалуй, стоит показать, где заканчивается код, который вы можете нагуглить и начинается профессия.

А у вас часто офис говно и большая чать начальников серьёзно думает что считать нужно с 1, исправляйтесь.

# Многовекторные графики анализа, часть 1.
## Plotly который DS забыли, потому что его надо писать на python.

Давным-давно в далёкой-далёкой галактике, в одном из первых уроков MLopen нам всем показали plotly из богоподобного фреймворка DASH, на котором написаны почти все приложения по "аналитике" на этой планете. Dashboard analytics отлично бьётся по любым поисковикам в разделе картинки, вот только доступность готовых решений напрочь отбила у общественности желание писать, что то сложное самому, зря. 

![Альтернативный текст](https://github.com/HorusHeresyHeretic/Algorithmic-data-analysis/blob/main/sync_or_die.jpg)

Это многовекторный график синхронизации процессов, который можно выжать из plotly. Необходимый для него import и ядро графика смотреть [здесь](https://github.com/HorusHeresyHeretic/Algorithmic-data-analysis/blob/main/syncrhonize_me.ipynb). Копипастом без служебной функции работать не будет. Остальное под свои данные сами напишите, если сможете.

Положения осей в графике не являються константой, в самых пиковых случаях линии тренда (синия и оранжевая) просто расходятся по вертикали как два сплошных потока событий. Также график отлично визуализирует все выбросы, которые выбиваються из общего ряда. Как и всё в dash он интерактивный и его можно рассылать по почте как самодостаточный html файл.

Бесценная вещь. Пошупать можно [здесь](https://raw.githubusercontent.com/HorusHeresyHeretic/Algorithmic-data-analysis/main/Относительно%20хорошо.html), но поскольку git глупый файл надо скачать и открыть в браузере.




Представьте себе, что у вас есть завод, на заводе автоматическая линия, в линии контроллеры, контроллеры управляют операциями, в которых есть заданные интервалы и это линия сбоит. А контроллеров штук 50-100 или 500.  

Или как вариант вы пытаетесь рассмотреть бизнес-процесс, в данном случае я визуализировал процесс эксплуатации ТС в масштабах одной из компаний Холдинга - всё как на ладони. В любой среде, в которой существует точка отчёта по времени этот график маст хев.

Чем ближе друг к другу линии тренда - тем более ритмично работает то, что вы рассматриваете, чем больше совпадений по вертикали выше линии тренда - тем выше общий процент операций, завершение которых происходит одномоментно и наоборот.

# Потоковые вычисления, часть 2.
## Перестаньте писать классы, если не умеете писать функции.

Pandas хорош, но кое чего в нём не хватает: встроенного интератора, который бы позволял применять потоковые вычисления к уникальным объектам внутри датафрейма. Конечно каждый DS решает эту проблему как умеет, но я считаю что мой вариант лучший. 

Для тех кто ничего не понял - объясняю: в Pandas нельзя просто так взъять и сказать, а нука примени 57 функций, 17 встроенных методов и 117 математических выражений к КАЖДОМУ уникальному объекту внутри датафрейма, который я, человек вижу.

Например у вас есть логи клиентов контакт-центра, у каждого клиента есть ID и десяток колонок справа, а вы хотите к каждому ID применить десяток математических методов, но так, чтобы при вычислении учитывалась вся дополнительная информация привязанная к этому ID (в колонках справа от него). 

Обычно пишут векторизацию - методы применяются к строке которую выдернули из датафрейма по индексу, а потом к следующей. Но есть метод проще (и уже давно, я придумал это ещё в 2018 гг). Поэтому встречайте - функция которая использует КЛЮЧ.

hard_nn это датафрейм который прогнали через фильтры и прочие радости жизни.

warp_field_generator это (ох лол) это генератор, который мы передаём в функцию.

Фактически это косплей векторизации по ключу в датафрейме, благодоря которому мы не только экономим ресурсы, но и..
![Альтернативный текст](https://github.com/HorusHeresyHeretic/Algorithmic-data-analysis/blob/main/мой%20старый%20костыль.jpg)

можем применить любые выражения, методы, другие фукнции и встроенные классы к объекту внутри датафрейма.
![Альтернативный текст](https://github.com/HorusHeresyHeretic/Algorithmic-data-analysis/blob/main/считай%20меня%20считай%20меня%20полностью.jpg)

и посмотреть что получилось в принтах дёрнув функцию, которая сама дёрнет генератор.
![Альтернативный текст](https://github.com/HorusHeresyHeretic/Algorithmic-data-analysis/blob/main/дебаг%20на%20принтах%20наше%20всё.jpg)

С одной стороны это удобно: можно написать большой блок различных операций, который вы хотите применить к объектам внутри датафрейма большой функцией, а потом гонять её генератором по всему датафрейму.  С другой стороны генератор который мы передали в фукнцию вычисления глупый, остановится как только засбоит одна из операций счисления в функции.

# Я осилил функцию векторизации, как с ней работать? часть 3.
## молодец, будешь великим программистом (а потом захочешь бросить всё это).

Если писать влоб то вывод таких фукнций будет выглядеть как варп, см пример.
![Альтернативный текст](https://github.com/HorusHeresyHeretic/Algorithmic-data-analysis/blob/main/няш%20мяш%20крым%20наш.jpg)

Поэтому вывод фукнции надо сложить заново в датафрейм, для этого надо использоать кеш, пример.

Дёргаём алгоритм вокруг Холта-Винтерса на 1К строк который также написан через генератор (возвращает total и roll) и обернут в функцию.
![Альтернативный текст](https://github.com/HorusHeresyHeretic/Algorithmic-data-analysis/blob/main/machine%20learning%20глупое%20модное%20слово.jpg)

(да да я знаю, 98% людей которым я показал это, кричали что то про инквизицию). Кеш это one = pd.DataFrame, складывать вывод фукнции будем туда. 
![Альтернативный текст](https://github.com/HorusHeresyHeretic/Algorithmic-data-analysis/blob/main/кеш%20в%20который%20не%20умеют%20почти%20все.jpg)

Для любителей кегли, могу показать значения среднеквадратичной ошибки на мусоре с кооф.вариации выше 50%, это дебаг на принтах 16 моделей, которые создаёються в рамках алгоритма на один объект предсказания.

![Альтернативный текст](https://github.com/HorusHeresyHeretic/Algorithmic-data-analysis/blob/main/это%20всё%20тот%20же%20алгоритм%20с%20дебагом%20на%20принтах.jpg)




















